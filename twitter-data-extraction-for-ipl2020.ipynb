{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "![](https://miro.medium.com/fit/c/1838/551/1*EVJyTyvcx_puOVJSscJveg.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install tweepy\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tweepy as tw # To extarct the twitter data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Requirements: You must have a twitter account**\n",
    "### STEP 1: Create a twitter app using this link (https://apps.twitter.com/app/new)\n",
    "### STEP 2: Once u create ur own app using step 1, You will get 2 keys which is unique to your account API KEY and API KEY SECRET\n",
    "### STEP 3: Run the below sections of code to extarct the twitter data!   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_api_key = 'Type your API KEY here '\n",
    "consumer_api_secret = 'Type your API KEY SECRET here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_api_key, consumer_api_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are trying to extract all the tweets made with the #ipl2020 hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = \"#ipl2020 -filter:retweets\" #Type you keywork here instead of #covidvaccine\n",
    "#You can fix a time frame with the date since and date until parameters\n",
    "date_since = \"2020-08-17\"\n",
    "date_until=\"2020-08-20\"\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"en\",\n",
    "              since=date_since,\n",
    "              until=date_until     \n",
    "              ).items(7500) #We instruct the cursor to return maximum of 7500 tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's retrieve the tweets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_copy = []\n",
    "for tweet in tqdm(tweets):\n",
    "    tweets_copy.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"New tweets retrieved: {len(tweets_copy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets extarct the necessary features for each tweet\n",
    "#### A standard set of features are been extracted here in this notebook!\n",
    "#### But still there are many features you can extract for an tweet. please refer this article to know about them(https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/tweet-object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for tweet in tqdm(tweets_copy):\n",
    "    hashtags = []\n",
    "    try:\n",
    "        for hashtag in tweet.entities[\"hashtags\"]:\n",
    "            hashtags.append(hashtag[\"text\"])\n",
    "    except:\n",
    "        pass\n",
    "    tweets_df = tweets_df.append(pd.DataFrame({'user_name': tweet.user.name, \n",
    "                                               'user_location': tweet.user.location,\\\n",
    "                                               'user_description': tweet.user.description,\n",
    "                                               'user_created': tweet.user.created_at,\n",
    "                                               'user_followers': tweet.user.followers_count,\n",
    "                                               'user_friends': tweet.user.friends_count,\n",
    "                                               'user_favourites': tweet.user.favourites_count,\n",
    "                                               'user_verified': tweet.user.verified,\n",
    "                                               'date': tweet.created_at,\n",
    "                                               'text': tweet.text, \n",
    "                                               'hashtags': [hashtags if hashtags else None],\n",
    "                                               'source': tweet.source,\n",
    "                                               'is_retweet': tweet.retweeted}, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv('ipl2020.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## And Voila! You now have the tweets you required for the given time frame! Kindly upvote the kernel if you find it useful!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
